{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a451881d-c7a4-4601-9348-0b66d6c67f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/gavin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/gavin/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ åŠ è½½ SemEval-2010 Task 8 æ•°æ®é›†...\n",
      "ğŸ“Š æ•°æ®é›†ä¸­å…±æœ‰ 8000 æ¡å¥å­ã€‚\n",
      "\n",
      "âœ‚ï¸ æå–å®ä½“ <e1> å’Œ <e2>...\n",
      "\n",
      "ğŸŸ¢ æå–å®ä½“çš„ä¸Šä½è¯ï¼ˆä½¿ç”¨ WordNetï¼‰...\n",
      "å¥å­ 1:\n",
      "   å®ä½“ e1: configuration â†’ ä¸Šä½è¯: ['design']\n",
      "   å®ä½“ e2: elements â†’ ä¸Šä½è¯: ['weather']\n",
      "å¥å­ 2:\n",
      "   å®ä½“ e1: child â†’ ä¸Šä½è¯: ['offspring']\n",
      "   å®ä½“ e2: cradle â†’ ä¸Šä½è¯: ['baby_bed']\n",
      "å¥å­ 3:\n",
      "   å®ä½“ e1: author â†’ ä¸Šä½è¯: ['maker']\n",
      "   å®ä½“ e2: disassembler â†’ ä¸Šä½è¯: ['No hypernym found']\n",
      "å¥å­ 4:\n",
      "   å®ä½“ e1: ridge â†’ ä¸Šä½è¯: ['convex_shape']\n",
      "   å®ä½“ e2: surge â†’ ä¸Šä½è¯: ['increase']\n",
      "å¥å­ 5:\n",
      "   å®ä½“ e1: student â†’ ä¸Šä½è¯: ['enrollee']\n",
      "   å®ä½“ e2: association â†’ ä¸Šä½è¯: ['social_activity']\n",
      "\n",
      "ğŸ’¾ ç»“æœå·²æˆåŠŸå¯¼å‡ºä¸º: semeval_entity_hypernyms.csv\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk.corpus import wordnet as wn\n",
    "from datasets import load_dataset\n",
    "import nltk\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "def load_semeval_data():\n",
    "    dataset = load_dataset(\"SemEvalWorkshop/sem_eval_2010_task_8\")\n",
    "    sentences = dataset['train']['sentence']\n",
    "    return sentences\n",
    "\n",
    "def extract_entities(sentences):\n",
    "    \"\"\"\n",
    "    æå– <e1> å’Œ <e2> æ ‡ç­¾å†…çš„å®ä½“\n",
    "    \"\"\"\n",
    "    entity_pairs = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        # æå– <e1> å’Œ <e2> çš„å†…å®¹\n",
    "        e1_match = re.search(r'<e1>(.*?)</e1>', sentence)\n",
    "        e2_match = re.search(r'<e2>(.*?)</e2>', sentence)\n",
    "\n",
    "        if e1_match and e2_match:\n",
    "            e1 = e1_match.group(1)\n",
    "            e2 = e2_match.group(1)\n",
    "            entity_pairs.append((e1, e2))\n",
    "        else:\n",
    "            entity_pairs.append((None, None))  # å¦‚æœæ‰¾ä¸åˆ°å®ä½“\n",
    "\n",
    "    return entity_pairs\n",
    "\n",
    "def get_best_hypernym(entity):\n",
    "\n",
    "    synsets = wn.synsets(entity, pos=wn.NOUN)\n",
    "    if not synsets:\n",
    "        return [\"No hypernym found\"]\n",
    "    \n",
    "    best_hypernym = None\n",
    "    highest_similarity = 0\n",
    "\n",
    "    # æ¯”è¾ƒæ¯ä¸ªåŒä¹‰è¯é›†çš„ç›¸ä¼¼åº¦\n",
    "    for syn in synsets:\n",
    "        for hypernym in syn.hypernyms():\n",
    "            similarity = syn.wup_similarity(hypernym)  # ä½¿ç”¨ Wu-Palmer ç›¸ä¼¼åº¦\n",
    "            if similarity and similarity > highest_similarity:\n",
    "                highest_similarity = similarity\n",
    "                best_hypernym = hypernym\n",
    "\n",
    "    return [best_hypernym.lemmas()[0].name()] if best_hypernym else [\"No hypernym found\"]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\" åŠ è½½ SemEval-2010 Task 8 æ•°æ®é›†...\")\n",
    "    sentences = load_semeval_data()\n",
    "    print(f\" æ•°æ®é›†ä¸­å…±æœ‰ {len(sentences)} æ¡å¥å­ã€‚\")\n",
    "\n",
    "    print(\"\\n æå–å®ä½“ <e1> å’Œ <e2>...\")\n",
    "    entity_pairs = extract_entities(sentences)\n",
    "\n",
    "    print(\"\\n æå–å®ä½“çš„ä¸Šä½è¯ï¼ˆä½¿ç”¨ WordNetï¼‰...\")\n",
    "    results = []\n",
    "\n",
    "    for idx, (e1, e2) in enumerate(entity_pairs):\n",
    "        e1_hypernyms = get_best_hypernym(e1) if e1 else [\"No entity found\"]\n",
    "        e2_hypernyms = get_best_hypernym(e2) if e2 else [\"No entity found\"]\n",
    "\n",
    "        results.append({\n",
    "            \"Sentence ID\": idx + 1,\n",
    "            \"Entity e1\": e1,\n",
    "            \"Entity e1 Hypernyms\": \", \".join(e1_hypernyms),\n",
    "            \"Entity e2\": e2,\n",
    "            \"Entity e2 Hypernyms\": \", \".join(e2_hypernyms)\n",
    "        })\n",
    "\n",
    "        if idx < 5:\n",
    "            print(f\"å¥å­ {idx+1}:\")\n",
    "            print(f\"   å®ä½“ e1: {e1} â†’ ä¸Šä½è¯: {e1_hypernyms}\")\n",
    "            print(f\"   å®ä½“ e2: {e2} â†’ ä¸Šä½è¯: {e2_hypernyms}\")\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    output_file = \"semeval_entity_hypernyms.csv\"\n",
    "    df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    print(f\"\\n ç»“æœå·²æˆåŠŸå¯¼å‡ºä¸º: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cd2f08-a319-4e61-bad6-5b74bbbaa876",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ab1e86-a832-40d5-a729-099459331067",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
